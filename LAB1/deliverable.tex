\documentclass[12]{article}
\usepackage[utf8]{inputenc}
\usepackage{cite}
\author{par4111 \\ Adrià Cabeza, Xavier Lacasa \\ Departament d' Arquitectura de Computadors}
\title{Lab 1: Experimental setup and tools}
\date{\today \\ 2018 - 19 PRIMAVERA}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{pgfplots}
\usepackage{listings}
\usepackage{color}
\usepackage{float}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\lstset{
	frame=tb,language=C,breaklines=true,numbers=none, commentstyle=\color{dkgreen}, stringstyle=\color{mauve}, tabsize=3,   showstringspaces=false,
  columns=flexible, 
}
\begin{document}
\maketitle
\vspace*{\fill}
\begin{center}
\includegraphics[scale=0.5]{images/UPClogo.png}
\end{center}

\newpage
\tableofcontents
\newpage
\section{Introduction}
In order to do properly this subject, first, we have to introduce some new concepts and hardware and software environment that we will use during this semester to do all laboratory assignments.  The following document contains an introductory approach, step by step introducing those concepts. We will introduce the \textit{Boada} architecture, some of the most important parallelism concepts and several tests to see its effects. 

\section{Experimental setup}
\subsection{Node architecture and memory}

\textit{Boada} is a multiprocessor server located at the Computer Architecture Department divided in different nodes, each of them with different architecture and diffferent uses. \textit{Boada} is composed of 8 nodes (from boada-1 to boada-8) and they can be grouped as the following table: 
\\
\begin{table}[h]
\begin{tabular}{|l|l|l|l|}
\hline
Node name    & Processor generation                & Interactive & Queue name \\ \hline
boada-1      & Intel Xeon E5645                    & Yes         & batch      \\
boada-2 to 4 & Intel Xeon E5645                    & No          & execution  \\
boada-5      & Intel Xeon E5-2620 v2 + Nvidia K40c & No          & cuida      \\
boada-6 to 8 & Intel Xeon E5-2609 v4               & No          & execution2 \\ \hline
\end{tabular}
\end{table}

However in this course we are going to use mainly from boada-1 to boada-4. The easiest way to obtain the information of the hardware used in each node is using the linux commands lscpu and lstopo(see Figure  ~\ref{fig:lstopto2} and ~\ref{fig:lstopto8}). This commands can be easily executed in the boada-1 node (because it is interactive), but if we want to use the other nodes we can use the submit-*.sh script provided by the PAR professors and use the queue system. \\
\medskip

\begin{figure}[h]
\centering  \includegraphics[width=.8\linewidth]{images/map-2.png}
  \caption{Boada-2 architecture outputed by lstopo.}
  \label{fig:lstopto2}
\end{figure}

\begin{figure}[h]
\centering
  \includegraphics[width=.8\linewidth]{images/map-8.png}
  \caption{Boada-8 architecture outputed by lstopo.}
  \label{fig:lstopto8}
\end{figure}

After creating the scripts and applying them to each of the nodes, we obtained the following hardware information: 


\begin{table}[h]
\centering    \begin{tabular}{|l||l|l|l|}
    \hline
                                        & boada-1 to boada-4    & boada-5   & boada-6 to boada-8    \\
    \hline\hline
    Number of sockets per node          & 2                     & 2         & 2                     \\
    \hline
    Number of cores per socket          & 6                     & 6         & 8                     \\
    \hline
    Number of threads per core          & 2                     & 2         & 1                     \\
    \hline
    L1-I cache size (per-core)          & 32 KB                 & 32 KB     & 32 KB                 \\    
    \hline
    L1-D cache size (per core)          & 32 KB                 & 32 KB     & 32 KB                 \\
    \hline
    L2 cache size (per-core)            & 256 KB                & 256 KB    & 256 KB                \\
    \hline
    Last-level cache size (per-socket)  & 12 MB                 & 15 MB     & 20 MB                 \\
    \hline
    Main memory  size (per socket)      & 12 GB                 & 31 GB     & 16 GB                 \\
    \hline
    Main memory size (per node)         & 23 GB                 & 63 GB     & 31 GB                 \\
    \hline
    \end{tabular}
\end{table}

\bigskip

The previous table gives us useful information that will be necessary in the future to properly use the \textit{boada} system and understand the parallelism decomposition and time we will get. 

\subsection{Sequential and parallel executions}

More often than not parallelism offers speed-ups in the execution time of applications. Sometimes, however, that extra speed is used to augment the problem size, which would not be possible otherwise.

In the two following sections we are going to see the differences of two different approaches to parallelism, \textbf{strong} and \textbf{weak}, applied to the \textit{pi\_omp.c} program.

\subsubsection{Strong scalability}

Strong scalabilty consists in increasing the numberer of processors while keeping the problem size the same. This reduces the amount of work each processor has to do, which speeds-up the execution.
Nonetheless, the speed-up is bounded by the parallelization of the program and the overhead generated when doing so. Usually a point is reached where adding processors has no further effect on the program or the overhead generated by further parallelizing the program is greater than the added speed-up. 

Per a cabar lo de stron scalability mirat aixo https://github.com/Fibernalia/PAR/blob/master/Lab0/First%20deliverable/First%20deliverable%20(correcci%C3%B3n).jpg


https://github.com/Fibernalia/PAR/blob/master/Lab0/First%20deliverable/First_deliverable_par2303.pdf
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/pi_omp-100000000-1-12-3-weak-boada-6.png}
 \caption{ \textit{pi\_omp} with 100000000 weak by boada-6}
  \label{fig:pi_ompboada6}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/pi_omp-1000000000-1-12-3-strong-boada-8.png}
 \caption{ \textit{pi\_omp} with 1000000000 strong by boada-8}
 \label{fig:pi_ompboada8}
\end{figure}

\subsubsection{Weak scalability}

Weak scalability takes a different approach. It takes advantage of the additional power gained by parallelizing the program to increase the problem size, so that while the speed-up stays more or less the same, the work done increases.
ARA HEM DE POSAR ELS GRÀFICS PELS DIFERENTS BOADAS PERO NO ELS PUC CREAR, ES GENEREN EN BLANC JKAHSDFUJAHFUJAHF
\section{Experimental setup}
\subsection{Introduction}
The objective of this laboratory is learn how to use Tareador, an environment to analyse the potential parallelilsm that can be obtained when a certain task decomposition is applied to a code. We will introduce how it works and we will experiment and analyse decomposition with a sequential code called 3DFFT.

\subsection{Analysis of task decompositions for 3DFFT}

Once we have seen the basic features in \textit{Tareador} we can now proceed to explore new tasks decompositions for a piece of code. Down below we will incrementally generate five new task decompositions and the potential parallelism ($T_1 / T_\infty$) from the task dependence graph generated by \textit{Tareador}. 
\\
To obtain $T_\infty$ we will assume that each instruction takes one time unit to execute and simulate the execution of the graph with a large number of processors.

Once we have created those tasks, we can visualize the dependency graph using \textit{Tareador}. Each node of the graph represents a task: diferents shapes and colours are used to identify task instances and each one is labeled with a task instance number and some important information like the number of instructions. Also the size of the shape reflects in some way its granularity. 
 
\begin{figure}[H]
\centering  \includegraphics[width=.8\linewidth, height=14cm, width=6cm]{images/dependency_graph0.png}
  \caption{Dependency graph for the original version.}
  \label{fig:Depencency0}
\end{figure}


\subsubsection{Version 1}

The first version consists in replacing the task named \texttt{ffts1\_and\_transpositions} with a sequence of finer grained tasks, one for each function invocation inside it. The modified code is the following: 
\\
\begin{lstlisting}
...
    tareador_start_task("0");
    ffts1_planes(p1d, in_fftw);
    tareador_end_task("0");

    tareador_start_task("1");
    transpose_xy_planes(tmp_fftw, in_fftw);
    tareador_end_task("1");

    tareador_start_task("2");
    ffts1_planes(p1d, tmp_fftw);
    tareador_end_task("2");

    tareador_start_task("3");	
    transpose_zx_planes(in_fftw, tmp_fftw);
    tareador_end_task("3");
    
    tareador_start_task("4");
    ffts1_planes(p1d, in_fftw);
    tareador_end_task("4");

    tareador_start_task("5");
    transpose_zx_planes(tmp_fftw, in_fftw);
    tareador_end_task("5");

    tareador_start_task("6");
    transpose_xy_planes(in_fftw, tmp_fftw);
    tareador_end_task("6");
\end{lstlisting}

Once we have created all these tasks, we have to execute the script \textit{./run-tareador.sh VERSION1} and visualize the task dependence graph, see Figure \ref{Dependency1st}. As we can see comparing the original graph, see Figure \ref{Depencency0}, now the shape that was associated to \texttt{ffts1\_and\_transpositions} has now been divided into several other shapes which represents more granularity. 

\begin{figure}[H]
\centering  \includegraphics[width=\linewidth, height=22cm, width=5cm]{images/dependency_graph1.png}
  \caption{Dependency graph for the first version.}
  \label{fig:Dependency1st}
\end{figure}


\subsubsection{Version 2}

The second version, starting from the first one, consists in replacing the definition of tasks associated to function invocations \texttt{ffts1\_planes} with fine-grained tasks defined inside the function body and associated to individual iterations of the k loop. The changes that have been made in the code for this version are the following ones: 
\\ \medskip
\begin{lstlisting}

void ffts1_planes(fftwf_plan p1d, fftwf_complex in_fftw[][N][N]) {
    int k,j;

    for (k=0; k<N; k++) {
     tareador_start_task("ffts1_planes_loop_k");
     for (j=0; j<N; j++) {
       fftwf_execute_dft( p1d, (fftwf_complex *)in_fftw[k][j][0], (fftwf_complex *)in_fftw[k][j][0]);
     }
     tareador_end_task("ffts1_planes_loop_k");
    }
}


int main(){
...
    tareador_start_task("1");
    transpose_xy_planes(tmp_fftw, in_fftw);
    tareador_end_task("1");

    ffts1_planes(p1d, tmp_fftw);

    tareador_start_task("3");	
    transpose_zx_planes(in_fftw, tmp_fftw);
    tareador_end_task("3");

    ffts1_planes(p1d, in_fftw);

    tareador_start_task("5");
    transpose_zx_planes(tmp_fftw, in_fftw);
    tareador_end_task("5");

    tareador_start_task("6");
    transpose_xy_planes(in_fftw, tmp_fftw);
    tareador_end_task("6");
...
}

\end{lstlisting}

As we can see in the outputed dependency graph given by the \textit{Tareador} our dependency graph has now changed and there are several more shapes. The task that previously was \texttt{ffts1\_planes} has been divided into several more. 
\begin{figure}[H]
\centering  \includegraphics[width=\linewidth , height=13cm, width=13cm ]{images/dependency_graph2.png}
  \caption{Dependency graph for the second version.}
  \label{fig:Depencency2nd}
\end{figure}


\subsubsection{Version 3}
The third version, starting from the second one, consists in replacing the definition of tasks associated to function invocations \texttt{transpose\_xy\_planes} and \texttt{transpose\_zx\_planes} with fine-grained tasks inside the corresponding body functions and associated to individual iterations of the k loop, similarly it was made in the second version. 
\begin{lstlisting}
void transpose_xy_planes(fftwf_complex  tmp_fftw[][N][N], fftwf_complex in_fftw[][N][N]) {
    int k,j,i;

    for (k=0; k<N; k++) {
     tareador_start_task("transpose_xy_planes_loop_k");
     for (j=0; j<N; j++) {
       for (i=0; i<N; i++)
       {
         tmp_fftw[k][i][j][0] = in_fftw[k][j][i][0];
         tmp_fftw[k][i][j][1] = in_fftw[k][j][i][1];
       }
     }
     tareador_end_task("transpose_xy_planes_loop_k"); 
   }
}

void transpose_zx_planes(fftwf_complex in_fftw[][N][N], fftwf_complex tmp_fftw[][N][N]) {
    int k, j, i;

    for (k=0; k<N; k++) {
    tareador_start_task("transpose_zx_planes_loop_k");
    for (j=0; j<N; j++) {
      for (i=0; i<N; i++)
       {
         in_fftw[i][j][k][0] = tmp_fftw[k][j][i][0];
         in_fftw[i][j][k][1] = tmp_fftw[k][j][i][1];
       }
     }
     tareador_end_task("transpose_zx_planes_loop_k");

    }
}

int main(){
...
    tareador_start_task("init_complex_grid");
    init_complex_grid(in_fftw);
    tareador_end_task("init_complex_grid");

    STOP_COUNT_TIME("Init Complex Grid FFT3D");

    START_COUNT_TIME;

    ffts1_planes(p1d, in_fftw);
    transpose_xy_planes(tmp_fftw, in_fftw);
    ffts1_planes(p1d, tmp_fftw);
    transpose_zx_planes(in_fftw, tmp_fftw);
    ffts1_planes(p1d, in_fftw);
    transpose_zx_planes(tmp_fftw, in_fftw);
    transpose_xy_planes(in_fftw, tmp_fftw);
...
}
\end{lstlisting}

Like in the previous cases, we can now see in the dependency graph our results and the level of granularity we are getting. 

\begin{figure}[H]
\centering  \includegraphics[width=\linewidth , height=13cm, width=13cm  ]{images/dependency_graph3.png}
  \caption{Dependency graph for the third version.}
  \label{fig:Depencency3rd}
\end{figure}

\subsubsection{Version 4}
The forth version, starting from the third one, consists in replacing the definition of tasks associated to function invocations \texttt{init\_complex\_grid}  with fine-grained tasks inside the corresponding body functions and associated to individual iterations of the k loop, similarly it was made in the previous version. 

\begin{lstlisting}
void init_complex_grid(fftwf_complex in_fftw[][N][N]) {
  int k,j,i;

  for (k = 0; k < N; k++) {
    tareador_start_task("transpose_init_complex_grid_loop_k");
    for (j = 0; j < N; j++) {
      for (i = 0; i < N; i++)
      {
        in_fftw[k][j][i][0] = (float) (sin(M_PI*((float)i)/64.0)+sin(M_PI*((float)i)/32.0)+sin(M_PI*((float)i/16.0)));
        in_fftw[k][j][i][1] = 0;
#if TEST
        out_fftw[k][j][i][0]= in_fftw[k][j][i][0];
        out_fftw[k][j][i][1]= in_fftw[k][j][i][1];
#endif
      }
    }
 
     tareador_end_task("transpose_init_complex_grid_loop_k"); 
 }
}
int main(){
...

    init_complex_grid(in_fftw);
    STOP_COUNT_TIME("Init Complex Grid FFT3D");

    START_COUNT_TIME;

    ffts1_planes(p1d, in_fftw);
    transpose_xy_planes(tmp_fftw, in_fftw);
    ffts1_planes(p1d, tmp_fftw);
    transpose_zx_planes(in_fftw, tmp_fftw);
    ffts1_planes(p1d, in_fftw);
    transpose_zx_planes(tmp_fftw, in_fftw);
    transpose_xy_planes(in_fftw, tmp_fftw);
...
}

\end{lstlisting}

\begin{figure}[H]
\centering  \includegraphics[width=\linewidth , height=13cm, width=13cm  ]{images/dependency_graph4.png}
  \caption{Dependency graph for the forth version.}
  \label{fig:Dependency4rth}
\end{figure}


\subsubsection{Version 5}
This is the final version; in this version we will explore even more finer-grained tasks. In order to continue this task we observed the forth figure given by \textit{Tareador} which corresponds to the forth version of the code. 

As we can see in the Figure \ref{Dependency4rth} the task granularity that has less granularity is the \textit{ffts1\_planes\_loop\_k} with 10305 instructions. So we deepen in the code of the corresponding function and we created tasks in a loop deeper than our first approach. 
\begin{lstlisting}

void ffts1_planes(fftwf_plan p1d, fftwf_complex in_fftw[][N][N]) {
    int k,j;
    for (k=0; k<N; k++) {
     for (j=0; j<N; j++) {
       tareador_start_task("ffts1_planes_loop_j");

        fftwf_execute_dft( p1d, (fftwf_complex *)in_fftw[k][j][0], (fftwf_complex *)in_fftw[k][j][0]);
    tareador_end_task("ffts1_planes_loop_j");
         }

    }
}


\end{lstlisting}
\bigskip

\begin{figure}[H]
\centering  \includegraphics[width=\linewidth , height=13cm, width=4cm  ]{images/dependency_graph5.png}
  \caption{Dependency graph for the final version.}
  \label{fig:Dependency5}
\end{figure}

\subsubsection{Comparison between version 4 and version 5}


\begin{large}
\begin{center}
Time comparison (in ns) between version 4 and version 5
\end{center}
\end{large}
\begin{table}[h]
\begin{center}
Number of processors 
\end{center}
\begin{tabular}{l|l|l|l|l|l|l|}
\cline{2-7}

                         & 1           & 2           & 4           & 8          & 16         & 32         \\ \hline
\multicolumn{1}{|l|}{v4} & 639.780.001 & 320.310.001 & 165.389.001 & 91.496.001 & 64.018.001 & 64.018.001 \\ \hline
\multicolumn{1}{|l|}{v5} & 639.780.001 & 321.493.001 & 172.584.001 & 99.126.001 & 53.554.001 & 44.356.001 \\ \hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/Time.png}
  \caption{Time comparison between v4 and v5.}
  \label{fig:PlotComparison}
\end{figure}

\begin{large}
\begin{center}
Speedup between version 4 and version 5
\end{center}
\end{large}

\begin{table}[h]
\begin{center}
Number of processors 
\end{center}
\begin{tabular}{l|l|l|l|l|l|l|}
\cline{2-7}
                              & 1 & 2              & 4              & 8              & 16            & 32            \\ \hline
\multicolumn{1}{|l|}{Speedup} & 1 & 0.99632029 & 0.95831015 & 0.92302725 & 1.1953915 & 1.4432771 \\ \hline
\end{tabular}
\end{table}


\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/Speedup.png}
  \caption{Speedup between v4 and v5.}
  \label{fig:PlotComparison}
\end{figure}


From this two plots we can observe that there's a moment when it does not matter how many processors you use, you cannot improve the execution time we can get. In the case of the fourth version we can see it clearly comparing the time we get with 16 processors and the time we get with 32. \\

Moreover, there is still another interesting point we can still analyse. Even though the fifth version had more finer-grained tasks (check Figure \ref{fig:Dependency5} when we use less than 16 processors v4 gets a better time execution. That could be justified with the time is focused for making the finer-grained tasks work together because of the overhead.  


\subsection{Summary}

To sum up, we show a table with all the data obtained with our experiments. We can see that in all the versions excepting for the first ones, we increase the parallelism.
\\
\medskip
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Version & $T_1 $ & $T_\infty$ & Parallelism \\ \hline
seq     & 639,780,001   & 639,707,001    &        1.00011411474     \\ \hline
v1      &  639,780,001  & 639,707,001  &         1.00011411474      \\ \hline
v2      & 639,780,001   & 361,190,001   &      1.77131149597      \\ \hline
v3      & 639,780,001   & 154,354,001&         4.14488770524    \\ \hline
v4      & 639,780,001   &  64,018,001   &        9.99375161683     \\ \hline
v5      &639,780,001     & 38,224,001  &        16.7376513254    \\ \hline
\end{tabular}
\end{table}

\section{Understanding the parallel execution}
In this final section we have used several \textit{Paraver} configurations to be able to understand better the parallel executions. For example there is the Statistics Configuration File, see Figures \ref{fig:3dfftomp_original_8} and \ref{fig:3dfftomp_original_1}, where we can see the \% of each part of the execution time. 





\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/3dfftomp_original_1.png}
  \caption{Statistics from the original 3dfftomp version with 1 processor. State\_profile configuration was used.}
  \label{fig:3dfftomp_original_1}
\end{figure}



\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/3dfftomp_original_8.png}
  \caption{Statistics from the original 3dfftomp version with 8 processors. State\_profile configuration was used.}
  \label{fig:3dfftomp_original_8}
\end{figure}

FER GRAFICA A PARTIR D'AQUEST VALORS; AIXÒ ES LA PRIMERA VERSIÓ 

Temps paral·lelitzat en un processador(per parts)
343,032.74 us
330,705.06 us
105,560.45 us
146,440.56 us
199,973.45 us
401,774.42 us
Total paralelitzat
1.527.486,68 us
Temps total un processador
2894642449 ns

 
Temps paral·lelitzat en el 8 processadors (per parts)
1,284,479.03 us
1,145,823.44 us
709,704.96 us
496,762.32 us
321,938.67 us
579,582.94 us
Total paralelitzat
4538291,36 us
Temps total 
1.400.960.654 ns 

%Our calculations have been made using the default configuration to get the total time, see Figures  and the ____ configuration to get the parallelizable time, see Figures 



\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/TempsParalVersio1Processador1.png}
  \caption{blablabla}
  \label{fig:tempsParalv1Proc1}
\end{figure}



\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/TempsVersio1Processador1.png}
  \caption{blablabla}
  \label{fig:tempsv1Proc1}
\end{figure}




\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/TempsVersio1Processador8.png}
  \caption{blablabla}
  \label{fig:tempsParalv1Proc8}
\end{figure}



\begin{figure}[H]
\centering  \includegraphics[width=\linewidth]{images/TempsParalVersio1Processador8.png}
  \caption{blablablabla}
  \label{fig:tempsParalv1Proc8}
\end{figure}


The results obtained are in the following table.
\begin{table}[H]
\begin{tabular}{|l|l|l|l|l|l|}
\hline \textbf{Version} & $\phi $ & $S_\infty$ & $T_1$ & $T_8$ & $S_8$ \\ \hline
initial version in \textit{3dfft\_omp.c} & & & & & \\ \hline
new version with improved $\phi$ & & & & & \\ \hline
final version with reduced parallelisation overhead & & & & &  \\ \hline

\end{tabular}
\begin{center}
$\phi = T_{par} / (T_{seq} + T_{par}) $
\end{center}
\end{table}

%he pensat que maybe podriem treure les conclusions ss\section{Conclusions}

\end{document}
